{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ltbjLVFH23HO"
   },
   "source": [
    "# Tensorflow에 필요한 추가 기능 실습\n",
    "\n",
    "이번 실습에서는 Tensorflow에서 제공하는 유용한 API들에 대해서 학습한다. <br>\n",
    "Tensorflow에는 다양한 API들이 있으나 실습에서는 아래 제시된 API들에 대해서만 소개할 것이다. 추가적으로 학습하고 싶다면 Tensorflow 공식 Documentation을 참고하면 된다. <br>\n",
    "- Callback 사용\n",
    "- 전체 모델을 저장하고 불러오는 방법\n",
    "- Regularization 방법\n",
    "\n",
    "\n",
    "mnist dataset을 이용한 간단한 classification 모델을 이용하며 이 API들을 적용해볼 것이다.<br>\n",
    "먼저 필요한 패키지들을 가져온다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "XbkCB_it23HP"
   },
   "outputs": [],
   "source": [
    "#필요한 패키지 import\n",
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OZCBRBFchht9"
   },
   "source": [
    "## Load data and Model Build\n",
    "keras datasets API를 이용하여 실습에 사용하기 위한 data를 로드하고, Sequential API를 통해 간단한 모델을 Build, Compile하자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "jT2jyDtNhht9"
   },
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "#Load data & simple preprocess\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "wY2RxUHihht-"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ceGeCuPW23HR"
   },
   "source": [
    "## Callback 함수를 통해 학습률 조정, 중간 가중치 저장하고, 학습 경과 확인하기\n",
    "\n",
    "callback함수를 통해서 학습을 진행하면서 도중에 Tensorboard로 학습 경과를 확인하고, 중간 가중치를 checkpoint에 저장을 하거나, 학습률을 조정해본다. <br>\n",
    "\n",
    "Keras에서 에폭 시작이나 배치 종료, 에폭 종료 시 동작을 구현하는데 유용하게 사용할 수 있다. 예를 들면 아래와 같다.\n",
    "\n",
    "- 정기적으로 또는 특정 정확도 임계 값을 초과할 때 모델 체크 포인트 생성\n",
    "- 훈련이 진행됨에 따라 learning rate 조정(Fine tuning 목적)\n",
    "- 훈련이 정체되는 것처럼 보일 때 훈련을 멈추기\n",
    "- Tensorboard에서 시각화용으로 활용하기 위한 학습 진행 경과를 저장한다.\n",
    "- Loss, Metric 등의 로그를 저장한다.\n",
    "- Custom message를 출력한다.\n",
    "\n",
    "callback을 사용하기 위해서는 리스트 형태로 callback 함수들을 저장한 뒤, fit()으로 전달해주면 된다. `tf.keras.callbacks.Callback` 라이브러리에 있는 built-in callback 함수들을 잘 활용한다.\n",
    "\n",
    "- ModelCheckpoint : 주기적으로 모델을 저장한다.\n",
    "- LearningRateScheduler: Epoch에 따라서 Learning rate를 조정한다.\n",
    "- EarlyStopping : validation metrics가 향상되지 않을 때 학습을 멈춘다.\n",
    "- TensorBoard : 시각화하기위해서 모델 log들을 주기적으로 작성해서 텐서보드로 보여준다.\n",
    "- CSVLogger : loss, metrics data의 stream들을 CSV 파일로 넘긴다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ZkzO0GNA23HR"
   },
   "outputs": [],
   "source": [
    "#checkpoint가 저장될 경로를 지정해준다.\n",
    "checkpoint_dir = './training_checkpoints_tfAPI'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "#학습률을 점점 줄이기 위한 함수\n",
    "def decay(epoch):\n",
    "    if epoch < 3:\n",
    "        return 1e-3\n",
    "    elif epoch >=3 and epoch < 7:\n",
    "        return 1e-4\n",
    "    else:\n",
    "        return 1e-5\n",
    "    \n",
    "#Custom Callback : Learning rate를 각 epoch 마다 print하는 callback함수 설정\n",
    "class PrintLR(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print(\"\\n Epoch {}'s Learning rate is {}\".format(epoch + 1, model.optimizer.lr.numpy()))\n",
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.TensorBoard(log_dir = './logs'),\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3), #loss를 관찰하다 training을 중간에 그만두게 할 수 있다.\n",
    "    tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_prefix, save_weights_only = True),\n",
    "    tf.keras.callbacks.LearningRateScheduler(decay),\n",
    "    PrintLR()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RVTy9SnS23HS",
    "outputId": "764b1690-df95-4a3b-893b-a2abdc8be390"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "   3/1875 [..............................] - ETA: 47s - loss: 2.3017 - accuracy: 0.1667  WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0019s vs `on_train_batch_end` time: 0.0081s). Check your callbacks.\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.3034 - accuracy: 0.9139\n",
      "\n",
      " Epoch 1's Learning rate is 0.0010000000474974513\n",
      "Epoch 2/2\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1486 - accuracy: 0.9571\n",
      "\n",
      " Epoch 2's Learning rate is 0.0010000000474974513\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e8b2c955e0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#학습을 진행할 때, 미리 선언한 콜백함수를 작동하게 만들어준다.\n",
    "#텐서보드 로그를 다운받은 후, 터미널에서 텐서보드를 실행한다.\n",
    "#tensorboard --logdir=path/to/log-directory\n",
    "\n",
    "model.fit(x_train, y_train, epochs=2, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "vaVG2sHV23HT",
    "outputId": "0df887a4-87e9-4af4-c0c9-f270b0241490"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['checkpoint',\n",
       " 'ckpt_1.data-00000-of-00001',\n",
       " 'ckpt_1.index',\n",
       " 'ckpt_2.data-00000-of-00001',\n",
       " 'ckpt_2.index']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(checkpoint_dir)\n",
    "\n",
    "#checkpoint들이 지정된 경로에 저장된 것을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "hO9JRnDe23HU",
    "outputId": "fb83ed10-accb-419d-9fc8-bf8659c86cde"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 1ms/step - loss: 0.1285 - accuracy: 0.9613\n"
     ]
    }
   ],
   "source": [
    "#가장 최근에 저장된 체크포인트를 불러와서 모델의 weight들에 저장한 후, test data에 대해 evaluate한다.\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "\n",
    "eval_loss, eval_acc = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6eGy8F-w23HU"
   },
   "source": [
    "## 전체 모델 저장 및 로딩하기\n",
    "위에서 설명한 Checkpoint의 경우 모델의 변수정보만 저장된다. 이는 학습 중간중간에 훈련 진행상황을 저장하기에는 적합하지만 모델을 사용하고 싶어하는 다른 사람에게 전달한다면, 그 사람이 변수 정보만 가지고 모델을 다시 구성하기는 쉽지 않은 일이다. 이러한 상황에 대한 해결방안으로 Weight 뿐만 아니라 모델의 전체 정보를 저장하는 방법이 있다.<br>\n",
    "해당 방법으로 저장할 경우, **모델의 아키텍처 및 구성, 훈련 중에 저장된 모델의 weight, 모델의 컴파일 정보, 옵티마이저와 그 상태**를 저장한다. 그렇기 때문에 모델을 별도로 Build, compile 하지 않고도 바로 활용가능하다. <br>\n",
    "<br>\n",
    "Keras를 이용할 경우 TensorFlow SavedModel 형식 또는 이전에 사용하던 Keras H5 형식으로 저장하는 방법이 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "OzX_Xbhj23HU",
    "outputId": "766e2fd6-ef12-4e37-958b-7c768030d47f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/assets\n",
      "INFO:tensorflow:Assets written to: saved_model/assets\n"
     ]
    }
   ],
   "source": [
    "#Tensorflow SavedModel 형식으로 모델을 저장하는 방법 -> 2가지 API 존재\n",
    "\n",
    "path = 'saved_model/'\n",
    "model.save(path) #1번째 API\n",
    "tf.keras.models.save_model(model, path) #2번째 API "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "YYb-9VtS23HV",
    "outputId": "3a820323-e65c-46a8-88a9-fd7a000249d2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['assets', 'keras_metadata.pb', 'saved_model.pb', 'variables']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('saved_model')\n",
    "#saved_model.pb에는 모델 아키텍처 및 훈련 구성(옵티마이저, loss & matric)이 저장된다.\n",
    "#가중치의 경우 variables 폴더에 저장된다.\n",
    "#Assets 폴더에는 Graph 생성에 필요한 정보들이 저장되어 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Rsph-hCH23HV",
    "outputId": "16e73a98-870f-4c43-8dd8-63425f799ca7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 1ms/step - loss: 0.1285 - accuracy: 0.9613\n",
      "loss : 0.12846051156520844, accuracy : 0.9613000154495239\n"
     ]
    }
   ],
   "source": [
    "#Saved model을 로드하고 Evaluate\n",
    "loaded_model = tf.keras.models.load_model(path)\n",
    "eval_loss, eval_acc = loaded_model.evaluate(x_test, y_test)\n",
    "\n",
    "print('loss : {}, accuracy : {}'.format(eval_loss, eval_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "YjTT55SK23HV",
    "outputId": "91403f55-b527-4968-9cfc-aab48310bcfb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 1ms/step - loss: 0.1285 - accuracy: 0.9613\n",
      "loss : 0.12846051156520844, accuracy : 0.9613000154495239\n"
     ]
    }
   ],
   "source": [
    "#이전 Keras H5 형태로 저장하는 방법 (옛날 방식)\n",
    "model.save(\"my_model.h5\")\n",
    "#단일 HDF5 파일로 저장된다. 이 경우, savedmodel과 비교했을 때, 외부 loss metric은 저장되지 않는다.\n",
    "#훈련을 재개하고 싶을 때 모델을 로드한 후, 외부 loss metric을 별도로 추가해야 한다.\n",
    "\n",
    "loaded_model = tf.keras.models.load_model(\"my_model.h5\")\n",
    "eval_loss, eval_acc = loaded_model.evaluate(x_test, y_test)\n",
    "\n",
    "print('loss : {}, accuracy : {}'.format(eval_loss, eval_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pF-iwXFs23HW"
   },
   "source": [
    "## Regularization 방법\n",
    "Keras의 regularizers API를 이용하면 과적합을 막을 수 있다. 각 Layer를 생성할 때 regularizer argument를 넣어주면 사용가능하다.<br>\n",
    "이와 별개로 Dropout layer를 추가하여 과적합을 막는 방식도 가능하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D4jGeEjc23HW"
   },
   "outputs": [],
   "source": [
    "#L1 regularization : LASSO\n",
    "#L2 regularization : Ridge\n",
    "#Dropout\n",
    "#Elastic Regularization\n",
    "#https://www.tensorflow.org/api_docs/python/tf/keras/regularizers\n",
    "    \n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "inputs = tf.keras.Input(shape=(784,))\n",
    "dense = tf.keras.layers.Dense(64, activation=\"relu\")\n",
    "x = dense(inputs)\n",
    "\n",
    "#Regularizer를 적용하고 싶다면 아래와 같이 Layer 생성시 regularizer를 넣어주자.\n",
    "#Dense layer의 경우 kernel_regularizer, bias_regularizer, activity_regularizer 등을 사용가능하다.\n",
    "#상세 내용은 Documentation을 참고하라. https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense\n",
    "layer = tf.keras.layers.Dense(64, kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01))\n",
    "x = layer(x)\n",
    "\n",
    "# Dropout layer를 추가하여 Overfitting을 방지할 수도 있다.\n",
    "dropout = tf.keras.layers.Dropout(0.3)\n",
    "x = dropout(x)\n",
    "outputs = tf.keras.layers.Dense(10, activation='softmax')(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GPCA6SRyhhuE"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Model(inputs = inputs, outputs=outputs, name=\"mnist_model\")\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gcru7E2123HW",
    "outputId": "b2efb17d-839d-4811-98a9-6a940e5d156c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mnist_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         [(None, 784)]             0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 55,050\n",
      "Trainable params: 55,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "taer1QMH23HW"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Practice_Tensorflow_API.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
